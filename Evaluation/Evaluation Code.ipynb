{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwGdEoHPxfUq"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tOL1fE1y1NQ5"
      },
      "outputs": [],
      "source": [
        "url = 'http://e36e-34-75-86-30.ngrok.io'\n",
        "# url = 'http://35.232.59.3:8080'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EyoyLZ5Fb6jh"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc3sb0hh1WRr"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "37s_KGZx1Y1H"
      },
      "outputs": [],
      "source": [
        "def recall_at_k(true_list,predicted_list,k=40):   \n",
        "      \n",
        "    return round(len([i for i in predicted_list[:k] if i in true_list]) / len(true_list), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cKfXEsr7ba4j"
      },
      "outputs": [],
      "source": [
        "def precision_at_k(true_list,predicted_list,k=40):     \n",
        "\n",
        "    return round(len([i for i in predicted_list[:k] if i in true_list]) / k, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a8icgTjbbesL"
      },
      "outputs": [],
      "source": [
        "def r_precision(true_list,predicted_list):\n",
        "\n",
        "    return round(len([i for i in predicted_list[:len(true_list)] if i in true_list]) / len(true_list), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pRqB7ZlpbgLP"
      },
      "outputs": [],
      "source": [
        "def reciprocal_rank_at_k(true_list,predicted_list,k=40):\n",
        "\n",
        "    ele = next((i for i, v in enumerate(predicted_list) if v in true_list), None)\n",
        "    if ele == None or ele > (k - 1):\n",
        "      return 0.000\n",
        "    else:\n",
        "      return round(1 / (ele + 1), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W7AxBt_Dbmv9"
      },
      "outputs": [],
      "source": [
        "def f_score(true_list,predicted_list,k=40):\n",
        "    \n",
        "    precision = precision_at_k(true_list,predicted_list,k)\n",
        "    recall = recall_at_k(true_list,predicted_list,k)\n",
        "    if precision == 0 and recall == 0:\n",
        "      return 0\n",
        "    else:\n",
        "      return round((2 * precision * recall) / (precision + recall), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Zv8v0xwHuCf8"
      },
      "outputs": [],
      "source": [
        "def average_precision(true_list, predicted_list, k=40):\n",
        "    true_set = frozenset(true_list)\n",
        "    predicted_list = predicted_list[:k]\n",
        "    precisions = []\n",
        "    for i,doc_id in enumerate(predicted_list):        \n",
        "        if doc_id in true_set:\n",
        "            prec = (len(precisions)+1) / (i+1)            \n",
        "            precisions.append(prec)\n",
        "    if len(precisions) == 0:\n",
        "        return 0.0\n",
        "    return round(sum(precisions)/len(precisions),3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PiMo6MELcCWy"
      },
      "outputs": [],
      "source": [
        "def evaluate(true_relevancy,predicted_relevancy,k,print_scores=True):   \n",
        "\n",
        "    recall_lst = []\n",
        "    precision_lst = []\n",
        "    f_score_lst = []\n",
        "    r_precision_lst = []\n",
        "    reciprocal_rank_lst = []\n",
        "    avg_precision_lst = []\n",
        "    metrices = {'recall@k':recall_lst,\n",
        "                'precision@k':precision_lst,\n",
        "                'f_score@k': f_score_lst,\n",
        "                'r-precision': r_precision_lst,\n",
        "                'MRR@k':reciprocal_rank_lst,\n",
        "                'MAP@k':avg_precision_lst}\n",
        "\n",
        "    for query, ground_true in true_relevancy:  \n",
        "      predicted = predicted_relevancy[query]\n",
        "\n",
        "      recall_lst.append(recall_at_k(ground_true,predicted,k=k))\n",
        "      precision_lst.append(precision_at_k(ground_true,predicted,k=k))\n",
        "      f_score_lst.append(f_score(ground_true,predicted,k=k))\n",
        "      r_precision_lst.append(r_precision(ground_true,predicted))\n",
        "      reciprocal_rank_lst.append(reciprocal_rank_at_k(ground_true,predicted,k=k))\n",
        "      avg_precision_lst.append(average_precision(ground_true,predicted,k=k))\n",
        "\n",
        "    if print_scores:\n",
        "        for name,values in metrices.items():\n",
        "                print(name,sum(values)/len(values))\n",
        "\n",
        "    return metrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kMlNlaHGcqMM"
      },
      "outputs": [],
      "source": [
        "def plot_metric_different_quieries(true_relevancy,predicted_relevancy,metrices_names,k):\n",
        "\n",
        "    for metric_name in metrices_names:\n",
        "      met = evaluate(true_relevancy,predicted_relevancy,k=k,print_scores=False)\n",
        "      met_list = met[metric_name]\n",
        "      plt.xlabel(\"Queries\")\n",
        "      plt.ylabel(\"Metric\")\n",
        "      plt.title(metric_name)\n",
        "      plt.plot([i+1 for i in range(len(met_list))], met_list)\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64uyqhEXvg7s"
      },
      "source": [
        "# Test PageRank and PageViews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk52tWbUW0-F"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from time import time\n",
        "\n",
        "try:\n",
        "  res = requests.post(url + '/get_pageview', json=[1, 3434750, 713, 1], timeout=35)\n",
        "  if res.status_code == 200:\n",
        "    pred_wids = res.json()\n",
        "    print(pred_wids)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  res = requests.post(url + '/get_pagerank', json=[1, 3434750, 713, 1], timeout=35)\n",
        "  if res.status_code == 200:\n",
        "    pred_wids = res.json()\n",
        "    print(pred_wids)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR8XxS4b1ZZq"
      },
      "source": [
        "# Test all queries with MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6MPq5mSc1Y4Z"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('queries_train.json', 'rt') as f:\n",
        "  queries = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K5h2YPO-uGVl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from time import time\n",
        "\n",
        "qs_res = []\n",
        "pred_wids = {}\n",
        "sum_duration = 0\n",
        "map25 = True\n",
        "duration35 = True\n",
        "for q, true_wids in queries.items():\n",
        "  duration, ap = None, None\n",
        "  t_start = time()\n",
        "  try:\n",
        "    res = requests.get(url + '/search', {'query': q}, timeout=35)\n",
        "    duration = time() - t_start\n",
        "    sum_duration += duration\n",
        "    if res.status_code == 200:\n",
        "      pred_wids[q] = [tup[0] for tup in res.json()]\n",
        "      ap = average_precision(true_wids, pred_wids[q])\n",
        "      if ap < 0.25: map25 = False \n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  if duration == None: duration35 = False\n",
        "  qs_res.append((q, duration, ap))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Duration < 35s : \" + str(duration35))\n",
        "print(\"AP@40 > 0.25   : \" + str(map25))\n",
        "print(\"AVG Duration   : \" + str(sum_duration/len(queries)) + \"\\n\")\n",
        "qs_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(queries.items(),pred_wids,k=40,print_scores=True)\n",
        "plot_metric_different_quieries(queries.items(),pred_wids,['precision@k','recall@k','f_score@k','r-precision','MRR@k','MAP@k'],k=40)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Run_Test_Frontend_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
